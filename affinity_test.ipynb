{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from numpy import fft\n",
    "from astropy.io import fits\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Layer, Dense, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELOW IS A FN THAT PULLS FITS FROM FOLDER IN DIRECTORY AND SAVES THE FITS IMAGE, IMAGE LABEL, AND LABEL DATA OF EACH FITS FILE AND TRUTHCAT FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_folder_path = '/Users/sofie/Desktop/Projects/rwl_sims/ellip_images'\n",
    "truthcat_folder_path = '/Users/sofie/Desktop/Projects/rwl_sims/ellip_txts'\n",
    "\n",
    "# Define a function to get the fits file data\n",
    "def fft_image_e(images_folder_path, truthcat_folder_path):\n",
    "    # Initialize dictionaries to store values: (item1_name: fits1 image, output_label), (item2_name: fits2 image, output_label), etc.\n",
    "    fft_data_dict = {}\n",
    "    real_image_dict = {}\n",
    "    ellipticity_data_dict = {}\n",
    "\n",
    "    # Iterate through the images directory to obtain data\n",
    "    for item in sorted(os.listdir(images_folder_path)):\n",
    "        if item.endswith('.png') and not item.endswith('psf.png'):\n",
    "            image_path = os.path.join(images_folder_path, item)\n",
    "            image = plt.imread(image_path)\n",
    "\n",
    "            # Fourier transform the  image\n",
    "            fourier_image_data = fft.fftshift(fft.fft2(image))            \n",
    "\n",
    "            # Store the fft data in a dictionary\n",
    "            if item not in fft_data_dict:\n",
    "                fft_data_dict[item] = {}\n",
    "            fft_data_dict[item]['fourier_image_data'] = fourier_image_data\n",
    "\n",
    "            # Store the real image data in a dictionary\n",
    "            if item not in real_image_dict:\n",
    "                real_image_dict[item] = {}\n",
    "            real_image_dict[item]['real_image_data'] = image\n",
    "\n",
    "    # Extract the output labels (mod_e header in truthcat FITS file)\n",
    "    for item in os.listdir(truthcat_folder_path):\n",
    "        if item.startswith('truthcat'):\n",
    "            truthcat_file_path = os.path.join(truthcat_folder_path, item)\n",
    "            truthcat_file = fits.open(truthcat_file_path)\n",
    "            hdr_data = truthcat_file[1].data\n",
    "           \n",
    "            # Grab mod_e values\n",
    "            ellipticity = hdr_data['mod_e']\n",
    "\n",
    "            # Add values to ellipticity value dictionary\n",
    "            if item not in ellipticity_data_dict:\n",
    "                ellipticity_data_dict[item] = {}\n",
    "            ellipticity_data_dict[item] = ellipticity\n",
    "\n",
    "            # Close the FITS file\n",
    "            truthcat_file.close()\n",
    "\n",
    "    # Add fourier and ellipticity data together to initialize input output label dict\n",
    "    for key in fft_data_dict:\n",
    "        fft_first_six_letters = key[:7]\n",
    "        # print(fft_first_six_letters)\n",
    "        for elli_key, elli_value in ellipticity_data_dict.items():\n",
    "            elli_first_six_letters = elli_key[9:16]\n",
    "            # print(elli_first_six_letters)\n",
    "            if fft_first_six_letters == elli_first_six_letters:\n",
    "                for item in elli_value:\n",
    "                    fft_data_dict[key]['ellipticity'] = item\n",
    "  \n",
    "    # print(fft_data_dict)\n",
    "    \n",
    "    # Define the path to save the pickle file\n",
    "    pickle_file_path = '/Users/sofie/Desktop/Projects/Dissertation_Program/test_pkl/example_test_run1.pkl'\n",
    "\n",
    "    # Dump all dictionaries into a single pickle file\n",
    "    with open(pickle_file_path, 'wb') as f:\n",
    "        pickle.dump((fft_data_dict, real_image_dict, ellipticity_data_dict), f)\n",
    "\n",
    "    return fft_data_dict, real_image_dict, ellipticity_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALIZING THE FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fft_image_e(images_folder_path, truthcat_folder_path)\n",
    "input_output_data_dict = data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALIZING THE INPUT, OUTPUT, AND IMAGE DATA, CONVERTING THE DATA INTO ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_output_data_list = []\n",
    "\n",
    "# Populate the list with data from the dictionaries\n",
    "for key, value in input_output_data_dict.items():\n",
    "\n",
    "    # Extract fourier_image_data value and ellipticity value from the nested dictionaries\n",
    "    fourier_image_data = value.get('fourier_image_data', None)\n",
    "    ellipticity = value.get('ellipticity', None)\n",
    "    \n",
    "    # Ensure both values are present before appending to input_output_data_array\n",
    "    if fourier_image_data is not None and ellipticity is not None:\n",
    "        input_output_data_list.append((fourier_image_data, ellipticity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPEND THE DATA TO LISTS TO MAKE IT EASIER TO DEAL WITH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fft_data = []\n",
    "output_e_data = []\n",
    "for data_tuple in input_output_data_list:\n",
    "    fourier_image_data = data_tuple[0]\n",
    "    ellipticity = data_tuple[1]\n",
    "    input_fft_data.append(fourier_image_data)\n",
    "    output_e_data.append(ellipticity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT THE DATA TO ARRAYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fft_data = np.array(input_fft_data)\n",
    "output_e_data = np.array(output_e_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPLIT THE DATA INTO TESTING, TRAINING, AND VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        input_fft_data, output_e_data, test_size=0.33, random_state=42)\n",
    "\n",
    "#Split the training data into training and validation data\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALIZE THE HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the hyperparameters:\n",
    "NumClasses = 10\n",
    "BatchLength = 16\n",
    "Size = [28, 28, 1]\n",
    "NumIteration = 40001\n",
    "LearningRate = 1e-4\n",
    "EvalFreq = 1000\n",
    "NumKernels = [16, 32, 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALIZE THE SPECTRAL POOLING SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spectral pooling size: (0 is 1/2, 1 is 6/8)\n",
    "specPoolSize = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE THE FOURIER ACTIVATION FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No change from the template found on GitHub\n",
    "def fourier_complex_relu(x):\n",
    "    real = tf.math.real(x)\n",
    "    imag = tf.math.imag(x)\n",
    "    return tf.complex(tf.cast(real*real+imag*imag > 0.1, tf.float32)*real, tf.cast(real*real+imag*imag > 0.1, tf.float32)*imag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE THE FOURIER CONVOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No change from the template found on GitHub\n",
    "# Setting up a convolution layer to process data already in the Fourier domain\n",
    "# This has been updated using the automated software put out by TF to go from TF1.x to TF2.x as best it can\n",
    "# Obvi since this is a custom code, although the fns have been updated, the syntax isn't TF2.x recommended yet\n",
    "def convolution_in_freq_domain_without_ifft(f_input, out_channels):\n",
    "    in_shape = f_input.get_shape()\n",
    "\n",
    "    # Define trainable biases\n",
    "    bias_r = tf.compat.v1.get_variable('BiasReal', [out_channels], dtype=tf.float32)\n",
    "    bias_c = tf.compat.v1.get_variable('BiasComp', [out_channels], dtype=tf.float32)\n",
    "    bias = tf.complex(bias_r, bias_c)\n",
    "\n",
    "    # Spectral pooling:\n",
    "    if specPoolSize == 0:\n",
    "        f_input = tf.slice(f_input, [0, int(in_shape[1] // 4), int(in_shape[2] // 4), 0], \n",
    "                           [-1, int(in_shape[1] // 2), int(in_shape[2] // 2), in_shape[-1]])\n",
    "    elif specPoolSize == 1:\n",
    "        f_input = tf.slice(f_input, [0, int(in_shape[1] // 8), int(in_shape[2] // 8), 0], \n",
    "                           [-1, int(in_shape[1]) - int(2 * in_shape[1] // 8), \n",
    "                            int(in_shape[2]) - int(2 * in_shape[2] // 8), in_shape[-1]])\n",
    "   \n",
    "    in_shape = f_input.get_shape()\n",
    "    w_r = tf.compat.v1.get_variable('w_r', [int(in_shape[1]), int(in_shape[2]), int(in_shape[3]), out_channels])\n",
    "    w_i = tf.compat.v1.get_variable('w_i', [int(in_shape[1]), int(in_shape[2]), int(in_shape[3]), out_channels])\n",
    "    w = tf.complex(w_r, w_i)\n",
    "\n",
    "    fourier_kernel = w\n",
    "    fourier_kernel = tf.tile(tf.expand_dims(fourier_kernel, 0), [BatchLength, 1, 1, 1, 1])\n",
    "    out = []\n",
    "\n",
    "    for ind in range(out_channels):\n",
    "        res = tf.multiply(f_input[:, :, :, :], fourier_kernel[:, :, :, :, ind])\n",
    "        res = tf.add(res, bias[ind])\n",
    "        res = tf.expand_dims(tf.reduce_sum(res, 3), -1)\n",
    "        out.append(res)\n",
    "    out = tf.concat(out, 3)\n",
    "    \n",
    "    norm_real_layer = tf.keras.layers.BatchNormalization()\n",
    "    norm_comp_layer = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    norm_real = norm_real_layer(tf.math.real(out), training=True)\n",
    "    norm_comp = norm_comp_layer(tf.math.imag(out), training=True)\n",
    "    \n",
    "    out = tf.complex(norm_real, norm_comp)\n",
    "    out = fourier_complex_relu(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Class Model\n",
    "class FourierCNN(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FourierCNN, self).__init__()\n",
    "        self.dense1 = keras.layers.Dense(32, activation=\"relu\")\n",
    "        self.dense2 = keras.layers.Dense(5, activation=\"softmax\")\n",
    "        self.dropout = keras.layers.Dropout(0.5)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dropout(x, training=training)\n",
    "        return self.dense2(x)\n",
    "\n",
    "model = FourierCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCRATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gwvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
